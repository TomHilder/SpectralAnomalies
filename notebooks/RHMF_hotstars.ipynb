{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ea1eada-579f-4edd-8b72-167b6d89643d",
   "metadata": {},
   "source": [
    "# Robust HMF on *SDSS-V BOSS* spectra of hot stars...\n",
    "...to find evidence of H-alpha emission.\n",
    "\n",
    "## Authors:\n",
    "- **David W. Hogg** (NYU) (MPIA) (Flatiron)\n",
    "- **Hans-Walter Rix** (MPIA)\n",
    "\n",
    "## To-do items:\n",
    "- Output a full table of EWs for all stars.\n",
    "- Make some method (perhaps in `rhmf.py`) to save and restore a Robust HMF model.\n",
    "- Fit Voigt profiles to emission lines maybe?\n",
    "- Iteratively remove emission-line stars from training sets.\n",
    "\n",
    "## Bugs:\n",
    "- Eliminate cool stars from training sets?\n",
    "- Eliminate wrong redshifts and bad wavelength solutions from the training sets?\n",
    "- Selection is bad -- SNR cut should be dropped to 20; maybe other cuts?\n",
    "- Code says there is a (BP-RP) color cut, but there isn't.\n",
    "- Plots show Bohr wavelengths, not correct NIST wavelengths, for the Hydrogen lines.\n",
    "- This needs a method to save a model and pick up where it left off.\n",
    "- Maybe RHMF is the wrong tool for this job?\n",
    "- Inconsistent variable names; inconsistent uses of underscores, directory names, file names, etc.\n",
    "- At test time and plotting, produces way too much logging output on the terminal (stdout).\n",
    "- Maybe should think about `zorder` inputs to plotting calls?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dda567f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.io import fits\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import os\n",
    "import concurrent.futures\n",
    "import matplotlib.pyplot as plt\n",
    "import rhmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b1821e-d4d7-43ea-b1d0-5495ef2e6c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "\n",
    "# this MUST have the strongest emission lines first.\n",
    "LINELIST = [(\"H-alpha\", 6564.6),\n",
    "            (\"H-beta\", 4861.36),\n",
    "            (\"H-gamma\", 4340.46),\n",
    "            (\"H-delta\", 4101.74)] # Is this correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c5e629-4385-4bc5-9e54-f322c7bed0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data choices\n",
    "bosstag = 'v6_2_1'\n",
    "cachedir = f'./boss_{bosstag}_star_cache'\n",
    "os.makedirs(cachedir, exist_ok=True)\n",
    "\n",
    "# Create subdirectory for plots\n",
    "plot_folder = cachedir + '/plots'\n",
    "os.makedirs(plot_folder, exist_ok=True)\n",
    "\n",
    "# Tiny weird github / overleaf interaction hack\n",
    "_ = os.system(\"chmod a+x ./make_pdf.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ff5044-fdf2-454a-a415-3222f084107f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model choices\n",
    "rank, nsigma = 24, 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6644a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define download functions\n",
    "\n",
    "# bad global variables! DELETE THESE FOR GITHUB\n",
    "user, password = None, None\n",
    "nfail = 0\n",
    "\n",
    "def download_one_file_from_df(args):\n",
    "    \"\"\"Download a single file from SDSS.\"\"\"\n",
    "    url, filename, user, password, cachedir = args\n",
    "    subdir = filename.split(\"-\")[1]\n",
    "    old_filepath = cachedir + \"/\" + filename\n",
    "    filepath = cachedir + \"/\" + subdir + \"/\" + filename\n",
    "    os.makedirs(cachedir + \"/\" + subdir, exist_ok=True)\n",
    "    \n",
    "    # Skip if already downloaded\n",
    "    if os.path.exists(old_filepath):\n",
    "        os.system(f\"mv -fv {old_filepath} {filepath}\")\n",
    "    if os.path.exists(filepath):\n",
    "        # print(f\"File {filepath} already exists, skipping\")\n",
    "        return filepath\n",
    "\n",
    "    try:\n",
    "        with requests.Session() as session:\n",
    "            response = session.get(url, auth=HTTPBasicAuth(user, password), timeout=30)\n",
    "            response.raise_for_status()\n",
    "            with open(filepath, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "        if np.random.uniform() < 0.02: # one in fifty\n",
    "            print(f\"Random example: File downloaded: {filepath}\")\n",
    "        return filepath\n",
    "    except Exception as e:\n",
    "        nfail += 1\n",
    "        assert nfail < 10\n",
    "        print(f\"Failed to download {filepath}: {e}\")\n",
    "        return None\n",
    "\n",
    "def download_files_from_df(df, user, password, dest_folder, boss_tag='v6_2_1', coadd_version='daily', max_workers=16):\n",
    "    \"\"\"Download multiple files from SDSS based on dataframe.\"\"\"\n",
    "    os.makedirs(dest_folder, exist_ok=True)\n",
    "    args_list = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        spec_file = row['SPEC_FILE']\n",
    "        fieldid = f\"{row['FIELD']:06d}\"\n",
    "        mjd = str(row['MJD'])\n",
    "        fieldidXXX = fieldid[:-3] + 'XXX'\n",
    "        url = (\n",
    "            f\"https://data.sdss5.org/sas/sdsswork/bhm/boss/spectro/redux/\"\n",
    "            f\"{boss_tag}/spectra/{coadd_version}/lite/{fieldidXXX}/{fieldid}/{mjd}/{spec_file}\"\n",
    "        )\n",
    "        args_list.append((url, spec_file, user, password, dest_folder))\n",
    "\n",
    "    print(f\"Starting attempts to download {len(args_list)} files\")\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        results = list(executor.map(download_one_file_from_df, args_list))\n",
    "    print(f\"Number successful: {sum([r is not None for r in results])} files\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba33d8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and examine the spAll file\n",
    "spallname = f'spAll-lite-{bosstag}.fits'\n",
    "summaryurl = f'https://data.sdss5.org/sas/sdsswork/bhm/boss/spectro/redux/{bosstag}/summary/daily/{spallname}.gz'\n",
    "summaryfile = cachedir + '/' + spallname + '.gz'\n",
    "summaryfile_uncompressed = cachedir + '/' + spallname\n",
    "\n",
    "if not os.path.exists(summaryfile_uncompressed):\n",
    "    if not os.path.exists(summaryfile):\n",
    "        print(f\"Downloading summary file from {summaryurl}\")\n",
    "        response = requests.get(summaryurl, auth=HTTPBasicAuth(user, password))\n",
    "        with open(summary_file, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"Summary file {summaryfile} downloaded\")\n",
    "    \n",
    "    # Decompress\n",
    "    os.system(f'gunzip -v {summaryfile}')\n",
    "    print(f\"Summary file {summaryfile} decompressed\")\n",
    "else:\n",
    "    print(f\"Summary file {summaryfile_uncompressed} already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb33fe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spAll data\n",
    "with fits.open(summaryfile_uncompressed) as hdul:\n",
    "    data = hdul[1].data\n",
    "if False:\n",
    "    print(\"=\"*70)\n",
    "    print(\"ALL AVAILABLE COLUMNS IN SUMMARY FILE\")\n",
    "    print(\"=\"*70)\n",
    "    columns = data.columns.names\n",
    "    for i, col in enumerate(columns):\n",
    "        print(f\"{i+1:3d}. {col}\")\n",
    "print(f\"rows: {len(data)}; columns: {len(data.columns.names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ddad07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a sample of spectra to download\n",
    "# Let's look for high-SNR spectra with BP_MAG - RP_MAG < 0.5 to examine\n",
    "df = pd.DataFrame({col: data[col].byteswap().newbyteorder() for col in ['SPEC_FILE', 'FIELD', 'MJD', 'SN_MEDIAN_ALL', 'BP_MAG', 'RP_MAG', 'PROGRAMNAME']})\n",
    "\n",
    "# Filter for high SNR and BP_MAG - RP_MAG < 0.5 spectra\n",
    "high_snr_df = df[(df['SN_MEDIAN_ALL'] > 35.) & (df['PROGRAMNAME'] == 'mwm_ob') ] #.head(50)  # Just 50 spectra for testing\n",
    "print(f\"Selected {len(high_snr_df)} spectra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164f6093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the sample spectra\n",
    "pathnames = download_files_from_df(high_snr_df, user, password, cachedir, boss_tag=bosstag, coadd_version='daily', max_workers=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2aeeef-3e19-4253-8865-37d5301b4e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make lists of strings\n",
    "# BUG: This probably fails if there are None values in pathnames\n",
    "filenames = np.array([p.split(\"/\")[-1] for p in pathnames])\n",
    "specnames = np.array([f[5:-5] for f in filenames])\n",
    "print(len(pathnames), filenames.shape, specnames.shape)\n",
    "print(pathnames[13], filenames[13], specnames[13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0e867e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make rectangular data, plus wavelength grid\n",
    "wavelength = None\n",
    "N = len(filenames)\n",
    "print(f\"reading {N} files...\")\n",
    "for i, filepath in enumerate(pathnames):\n",
    "    \n",
    "    try:\n",
    "        with fits.open(filepath) as hdul:\n",
    "            if len(hdul) > 1 and hasattr(hdul[1], 'data'):\n",
    "                spec_data = hdul[1].data\n",
    "                loglam = spec_data['LOGLAM']\n",
    "                fl = spec_data['FLUX']\n",
    "                iv = spec_data['IVAR']\n",
    "                wa = 10**loglam\n",
    "                if wavelength is None:\n",
    "                    wavelength = wa\n",
    "                    M = len(wavelength)\n",
    "                    flux = np.ones((N, M))\n",
    "                    ivar = np.zeros_like(flux)\n",
    "                if np.allclose(wa, wavelength):\n",
    "                    flux[i] = fl / np.median(fl)\n",
    "                    ivar[i] = iv * np.median(fl) ** 2\n",
    "                else:\n",
    "                    print(f\"  Dropped {filepath}: bad wavelength grid\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  Dropped {filepath}: {e}\")\n",
    "\n",
    "print(\"data blocks:\", flux.shape, ivar.shape, np.prod(flux.shape))\n",
    "print(\"bad pixels:\", np.sum(~ np.isfinite(flux)), np.sum(~ np.isfinite(ivar)),\n",
    "      np.sum(ivar <= 0.) / np.prod(flux.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ca7d3e-0d8f-4347-8ca2-8a39c6056421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim data\n",
    "good = (wavelength > 3700) & (wavelength < 10300) # magic\n",
    "wavelength = wavelength[good]\n",
    "flux = flux[:, good]\n",
    "ivar = ivar[:, good]\n",
    "print(flux.shape, ivar.shape, wavelength.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ce1261-6f4e-4c2d-a17c-9a549b4ccd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# floor and ceil the ivars ## HACK\n",
    "maxivar = 1.e4 / flux ** 2 # magic -- nothing is known to better than 1 percent\n",
    "ivar = np.clip(ivar, 0., maxivar)\n",
    "maxivar = 1.e5 / np.median(flux, axis=1) ** 2 # magic -- nothing is known to better than 0.3 percent on average\n",
    "minivar = 1.e-5 / np.median(flux, axis=1) ** 2 # magic -- there is trivial information even at useless pixels\n",
    "ivar = np.clip(ivar, minivar[:, None], maxivar[:, None])\n",
    "print(np.min(ivar), np.max(ivar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da651bcd-9d85-4e36-b955-21e21af09cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make two disjoint subsets, A and B\n",
    "N, M = flux.shape\n",
    "rng = np.random.default_rng(17) # the most random number\n",
    "foo = np.random.uniform(size=N)\n",
    "A = foo < np.median(foo)\n",
    "B = np.logical_not(A)\n",
    "print(np.sum(A), np.sum(B), ~np.any(np.logical_and(A, B)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33901f65-2d36-4533-af94-c4d093b62e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target 1500-star training sets; everything goes in a test set\n",
    "Aidxfull = np.arange(N)[A]\n",
    "Bidxfull = np.arange(N)[B]\n",
    "factor = len(Aidxfull) // 1500\n",
    "Aidx = Aidxfull[::factor]\n",
    "Bidx = Bidxfull[::factor]\n",
    "print(len(Aidxfull), len(Bidxfull), len(Aidx), len(Bidx), np.all(A[Aidxfull]), np.all(B[Bidxfull]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d08f864-5660-4e32-a8bc-9bf2781b554f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting utility: Hydrogen recombination lines\n",
    "\n",
    "def hydrogen_line(n_upper, n_lower):\n",
    "    R_H = 10973731.568157 # (12) per meter; Wikipedia\n",
    "    wave_number = R_H * (1/n_lower**2 - 1/n_upper**2) # per meter\n",
    "    return (1. / np.abs(wave_number)) * 1.e10 # Angstrom\n",
    "\n",
    "def plot_hydrogen_lines(ax):\n",
    "    # plt.axvline(6564.6, color=\"g\", lw=0.5, alpha=0.23) # true H-alpha rather than computed\n",
    "    for n1 in (2, 3):\n",
    "        for n2 in range(n1 + 1, n1 + 18): # magic\n",
    "            ax.axvline(hydrogen_line(n2, n1), color=\"b\", lw=0.5, alpha=0.23, zorder=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441df86a-05e2-423a-8821-368f529b4ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting utility: Hogg cares about wavelength axes.\n",
    "\n",
    "def hogg_wavelength_axis(ax, ws):\n",
    "    plot_hydrogen_lines(ax)\n",
    "    ax.semilogx()\n",
    "    ticks = [3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000]\n",
    "    ticklabels = [str(tick) for tick in ticks]\n",
    "    ax.set_xticks(ticks, ticklabels)\n",
    "    ax.set_xlim(np.min(ws), np.max(ws))\n",
    "    # ax.set_xlim(6500, 6600) # zoom in\n",
    "    ax.set_xlabel('wavelength')\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfda24e3-3689-4fd4-a21b-e5158596283a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the eigenvectors of a model\n",
    "\n",
    "def plot_G(model, waves, title):\n",
    "    plt.figure(figsize=(12,8))\n",
    "    for k, g in enumerate(model.G):\n",
    "        plt.step(waves, 10. * g + k,\n",
    "                 where='mid', lw=0.5, alpha=0.90)\n",
    "    plt.ylim(-1., model.K)\n",
    "    ax = hogg_wavelength_axis(plt.gca(), waves)\n",
    "    plt.title(title)\n",
    "    fn = plot_folder + \"/\" + \"_\".join(title.split(\" \")) + \".png\"\n",
    "    print(f\"writing file {fn}\")\n",
    "    plt.savefig(fn)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea5da0b-8b60-47d4-ac27-82db13834362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a spectrum and a synthetic spectrum and residuals\n",
    "\n",
    "def plot_one_spectrum(waves, flux, ivar, name, prefix, synth=None, verbose=False, legend=None):\n",
    "    f = plt.figure(figsize=(12, 4))\n",
    "    plt.axhline(0., lw=0.5, color='k', alpha=0.45)\n",
    "    plt.step(waves, flux,\n",
    "             where='mid', color='k', lw=0.5, alpha=0.90)\n",
    "    tiny = 0.01 / np.median(flux) ** 2\n",
    "    flhi = flux + 1. / np.sqrt(ivar + tiny)\n",
    "    fllo = flux - 1. / np.sqrt(ivar + tiny)\n",
    "    plt.fill_between(waves, fllo, flhi,\n",
    "                     step='mid', color='k', alpha=0.23)\n",
    "    if synth is not None:\n",
    "        plt.step(waves, flux - synth,\n",
    "                 where='mid', color='k', lw=0.5, alpha=0.90)\n",
    "        plt.step(waves, synth,\n",
    "                 where='mid', color='r', lw=0.5, alpha=0.90)\n",
    "        plt.step(waves, np.zeros_like(flux),\n",
    "                 where='mid', color='r', lw=0.5, alpha=0.90)\n",
    "\n",
    "    # adjust axes\n",
    "    foo = np.nanmedian(flux)\n",
    "    plt.ylim(-0.5 * foo, 2.5 * foo)\n",
    "    plt.ylabel('flux')\n",
    "    plottitle = name\n",
    "    if legend is not None:\n",
    "        plottitle = plottitle + \" \" + legend\n",
    "    plt.title(plottitle)\n",
    "    hogg_wavelength_axis(plt.gca(), waves)\n",
    "\n",
    "    # Save plot\n",
    "    plot_filename = plot_folder + '/' + prefix + name + '.png'\n",
    "    plt.savefig(plot_filename)\n",
    "    plt.close(f)\n",
    "    if verbose:\n",
    "        print(f\"  Plot saved: {plot_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc9fb48-ddab-49ea-9010-4f833c21d8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make test step but with a list of lines held out (like, say, H-alpha, H-beta, H-delta)\n",
    "\n",
    "def censored_cross_test(Y, W, waves, models, lines, delta):\n",
    "    W_line = 1. * W # copy\n",
    "    for line in lines:\n",
    "        near_line = (waves > (line - delta)) & (waves < (line + delta))\n",
    "        W_line[:, near_line] = 0.\n",
    "    return cross_test(Y, W_line, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f40285-387b-4cc5-8e2f-880bab46b17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross test: Test A objects with model B, and B objects with model A.\n",
    "\n",
    "def cross_test(Y, W, models):\n",
    "    assert len(models) == 2\n",
    "    synth = np.zeros_like(Y) + np.nan\n",
    "    print(\"cross_test(): synthesizing with\", np.sum(np.isnan(synth)), \"pixels to go\")\n",
    "    for model, _, trainidx, _ in models:\n",
    "        for i in trainidx:\n",
    "            synth[i] = model.test(Y[i], W[i])\n",
    "        print(\"cross_test(): synthesizing with\", np.sum(np.isnan(synth)), \"pixels to go\")\n",
    "    return synth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e663454a-2461-41ab-bfbb-089e3db4478e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# punk the rhmf model to do robust polynomial fitting\n",
    "# the requirement to do this shows that I am living my life wrong\n",
    "\n",
    "def robust_polyfit(ys, ws, xs, degree, nsigma=5.0):\n",
    "    design = np.vstack([xs ** d for d in range(degree + 1)])\n",
    "    poly = rhmf.RHMF(degree + 1, nsigma, G=design)\n",
    "    poly.M = len(xs)\n",
    "    poly.trained = True\n",
    "    return poly.test(ys, ws)\n",
    "\n",
    "def continuum_at_line(inys, inws, inxs, line):\n",
    "    near = np.abs(inxs - line) < 300 # magic\n",
    "    ys = np.append(inys[near], 0.) # hackitey hack\n",
    "    ws = np.append(inws[near], 0.)\n",
    "    xs = np.append(inxs[near], line)\n",
    "    verynear = np.abs(xs - line) < 10 # magic\n",
    "    ws[verynear] = 0.\n",
    "    return robust_polyfit(ys, ws, xs, 2)[-1]\n",
    "\n",
    "def integrate_line(dys, ws, xs, line):\n",
    "    \"\"\"\n",
    "    ## bugs:\n",
    "    - assumes terrible things about `xs`.\n",
    "    - has a terrible (but empirical) uncertainty analysis\n",
    "    \"\"\"\n",
    "    dxs = 0.5 * np.abs(xs - np.roll(xs, 1)) + 0.5 * np.abs(np.roll(xs, -1) - xs)\n",
    "    dxs[0], dxs[-1] = 0., 0.\n",
    "    close = np.abs(xs - line) < 400.0 # too far?\n",
    "    vvnear = np.abs(xs - line) < 4.0 # too close?\n",
    "    dyvar = np.percentile(dys[close] ** 2, 68) # woah cray\n",
    "    return np.sum(dys[vvnear] * dxs[vvnear]), np.sqrt(np.sum(dyvar * dxs[vvnear] * dxs[vvnear]))\n",
    "\n",
    "def line_ew(ys, ws, xs, ss, line):\n",
    "    flux, flerr = integrate_line(ys - ss, ws, xs, line)\n",
    "    cont = continuum_at_line(ys, ws, xs, line)\n",
    "    return flux / cont, flerr / cont\n",
    "\n",
    "def measure_all_line_ews(Y, W, waves, S):\n",
    "    N = len(Y)\n",
    "    M = len(LINELIST)\n",
    "    ews = np.zeros((N, M)) + np.nan\n",
    "    ewerrs = np.zeros((N, M)) + np.nan\n",
    "    for i in range(N):\n",
    "        if i % 10000 == 0:\n",
    "            print(\"measure_all_line_ews:\", i)\n",
    "        foo = [line_ew(Y[i], W[i], waves, S[i], line) for _, line in LINELIST]\n",
    "        ews[i] = [f[0] for f in foo]\n",
    "        ewerrs[i] = [f[1] for f in foo]\n",
    "    return ews, ewerrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d35616-6575-4a2c-958f-452ead237a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the full train and test pipeline\n",
    "\n",
    "def train_and_test(Y, W, waves, names, models, maxiter=10):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    # train step\n",
    "    for model, idx, idxfull, label in models:\n",
    "        print(label)\n",
    "        model.train(Y[idx], W[idx], maxiter=maxiter)\n",
    "        plot_G(model, waves, label)\n",
    "        plt.show()\n",
    "\n",
    "    # test step\n",
    "    censor_lines = [foo[1] for foo in LINELIST] # H-alpha first!\n",
    "    delta = 4. # Angstroms, magic\n",
    "    synth_ex_lines = censored_cross_test(Y, W, waves, models, censor_lines, delta)\n",
    "\n",
    "    # measure EWs\n",
    "    ews, ewerrs = measure_all_line_ews(flux, ivar, wavelength, synth_ex_lines)\n",
    "\n",
    "    # choose interesting objects to plot -- note terrible `good` hacks.\n",
    "    good = ((ews[:,1] / ewerrs[:,1]) > -1.) & ((ews[:,0] / ewerrs[:,0]) > 5.)\n",
    "    foo = np.linspace(0.0, 3.0, 300)\n",
    "    bar = np.abs(ews[good, 0][:, None] - foo[None, :])\n",
    "    idx = np.argmin(bar, axis=0)\n",
    "    idx = np.unique(idx)\n",
    "    idx = (np.arange(len(ews))[good])[idx]\n",
    "\n",
    "    # make plots\n",
    "    prefix = \"halpha_emitter_\"\n",
    "    pattern = f\"{plot_folder}/{prefix}*.png\"\n",
    "    os.system(f\"rm -f {pattern}\")\n",
    "    for i in idx:\n",
    "        thisprefix = prefix + f\"{ews[i, 0]:06.2f}_\"\n",
    "        legend = f\"H-alpha EW = {ews[i, 0]:05.2f}+/-{ewerrs[i, 0]:4.2f} Ang\"\n",
    "        plot_one_spectrum(waves, Y[i], W[i], names[i], thisprefix, synth=synth_ex_lines[i], legend=legend)\n",
    "    os.system(f\"./make_pdf.py {pattern} foo.pdf\")\n",
    "    return synth_ex_lines, ews, ewerrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5567b9-d1ea-4b1a-8ae7-d8051f35ecb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start models\n",
    "# format of each entry of `models` is `(model, train_indices, test_indices, name)`\n",
    "models = [(rhmf.RHMF(rank, nsigma), Aidx, Bidxfull, \"model A\"),\n",
    "          (rhmf.RHMF(rank, nsigma), Bidx, Aidxfull, \"model B\")]\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51526b4c-9e71-425a-8475-9643d553f8ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# start training\n",
    "synth, ews, ewerrs = train_and_test(flux, ivar, wavelength, specnames, models, maxiter=10)\n",
    "print(synth.shape, ews.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2121d8d1-027c-4f4b-9ae3-7d13213fc94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "good = (ewerrs[:, 0] < 0.1) & (ewerrs[:, 1] < 0.1)\n",
    "plt.axvline(0., color=\"k\", lw=1, alpha=0.5)\n",
    "plt.axhline(0., color=\"k\", lw=1, alpha=0.5)\n",
    "plt.scatter(ews[good, 0], ews[good, 1], color=\"k\", s=2, alpha=0.45)\n",
    "plt.axis(\"equal\")\n",
    "plt.xlim(-2., 20.)\n",
    "plt.ylim(-1., 10.)\n",
    "plt.xlabel(\"H-alpha EW (Ang)\")\n",
    "plt.ylabel(\"H-beta EW (Ang)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffbcac0-c382-4487-a1a0-a18fd4ed6630",
   "metadata": {},
   "outputs": [],
   "source": [
    "good = (ewerrs[:, 0] < 0.1) & (ewerrs[:, 1] < 0.1)\n",
    "plt.axvline(0., color=\"k\", lw=1, alpha=0.5)\n",
    "plt.axhline(0., color=\"k\", lw=1, alpha=0.5)\n",
    "plt.scatter(ews[good, 0], ews[good, 1] / ews[good, 0], color=\"k\", s=2, alpha=0.45)\n",
    "plt.xlim(-2., 20.)\n",
    "plt.ylim(-0.01, 0.5)\n",
    "plt.xlabel(\"H-alpha EW (Ang)\")\n",
    "plt.ylabel(\"H-beta EW / H-alpha EW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce75d5d-1fc2-40fd-88a1-6d257b2a7594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train even more\n",
    "for t in range(30):\n",
    "    synth, ews, ewerrs = train_and_test(flux, ivar, wavelength, specnames, models, maxiter=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a637fe-ee67-42ee-94b8-3e870a3b6480",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
