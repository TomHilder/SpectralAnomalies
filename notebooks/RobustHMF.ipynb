{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMF2VZsA02J5WO0sdf60G92",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidwhogg/RVSanomalies/blob/main/notebooks/RobustHMF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Robust Heteroskedastic Matrix Factorization\n",
        "A robust-PCA-like model that knows about observational uncertainties\n",
        "\n",
        "## Author:\n",
        "- **David W. Hogg** (NYU) (MPIA) (Flatiron)\n",
        "\n",
        "## Dependencies:\n",
        "- `pip3 install jax matplotlib astropy astroquery`\n",
        "\n",
        "## Issues:\n",
        "- Not yet written.\n",
        "- Assumes rectangular data with known uncertainties."
      ],
      "metadata": {
        "id": "oai5DwmLtA-H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PheEt-VFs-cP"
      },
      "outputs": [],
      "source": [
        "# jax related\n",
        "import jax.numpy as jnp\n",
        "import jax\n",
        "jax.config.update(\"jax_enable_x64\", True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install astropy\n",
        "!pip install astroquery"
      ],
      "metadata": {
        "id": "0_cdZOpmXhR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data-gathering and plotting related\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from astroquery.gaia import Gaia\n",
        "from astropy.table import Table\n",
        "import os\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "plt.rcParams['font.size'] = 12"
      ],
      "metadata": {
        "id": "PNHWYTqOT0gH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_rvs_sources_gspphot(teff_min=4810, teff_max=6200,\n",
        "                            logg_min=1.0, logg_max=3.0,\n",
        "                            grvs_mag_max=11.0, n_sources=500):\n",
        "    query = f\"\"\"\n",
        "    SELECT TOP {n_sources}\n",
        "        source_id, ra, dec, phot_g_mean_mag, grvs_mag,\n",
        "        radial_velocity, radial_velocity_error,\n",
        "        teff_gspphot, logg_gspphot, mh_gspphot,\n",
        "        bp_rp, parallax\n",
        "    FROM gaiadr3.gaia_source\n",
        "    WHERE has_rvs = 't'\n",
        "    AND grvs_mag <= {grvs_mag_max}\n",
        "    AND teff_gspphot BETWEEN {teff_min} AND {teff_max}\n",
        "    AND logg_gspphot BETWEEN {logg_min} AND {logg_max}\n",
        "    AND teff_gspphot IS NOT NULL\n",
        "    AND logg_gspphot IS NOT NULL\n",
        "    AND radial_velocity IS NOT NULL\n",
        "    ORDER BY grvs_mag ASC\n",
        "    \"\"\"\n",
        "    job = Gaia.launch_job_async(query)\n",
        "    sources = job.get_results()\n",
        "    print(f\"\\nFound {len(sources)} sources matching criteria\")\n",
        "    return sources"
      ],
      "metadata": {
        "id": "8aymaZ0yZKHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    'teff_min': 8000,\n",
        "    'teff_max': 10000,\n",
        "    'logg_min': 1.0,\n",
        "    'logg_max': 5.0,\n",
        "    'grvs_mag_max': 11.0,\n",
        "    'n_sources': 200\n",
        "}\n",
        "sources = find_rvs_sources_gspphot(**params)"
      ],
      "metadata": {
        "id": "Uz35ejRgXYIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_rvs_spectrum(source_id, output_dir=\"rvs_spectra_cache\"):\n",
        "    \"\"\"\n",
        "    Download RVS spectrum for a single source.\n",
        "    Returns wavelength and flux arrays.\n",
        "    \"\"\"\n",
        "    # Check if spectrum already exists in cache\n",
        "    cache_file = os.path.join(output_dir, f\"rvs_{source_id}.npz\")\n",
        "    if os.path.exists(cache_file):\n",
        "        data = np.load(cache_file)\n",
        "        return data['wavelength'], data['flux'], data['flux_error']\n",
        "    try:\n",
        "        # Download spectrum\n",
        "        retrieval_type = 'RVS'\n",
        "        data_structure = 'INDIVIDUAL'\n",
        "        data_release = 'Gaia DR3'\n",
        "\n",
        "        datalink_products = Gaia.load_data(\n",
        "            ids=[str(source_id)],\n",
        "            data_release=data_release,\n",
        "            retrieval_type=retrieval_type,\n",
        "            data_structure=data_structure,\n",
        "            verbose=False\n",
        "        )\n",
        "\n",
        "        if not datalink_products:\n",
        "            return None, None\n",
        "\n",
        "        product_key = f\"RVS-Gaia DR3 {source_id}.xml\"\n",
        "\n",
        "        if product_key not in datalink_products:\n",
        "            return None, None\n",
        "\n",
        "        # Extract spectrum\n",
        "        votable = datalink_products[product_key][0]\n",
        "        spectrum_table = votable.to_table()\n",
        "\n",
        "        wavelength = np.array(spectrum_table['wavelength'])  # in nm\n",
        "        flux = np.array(spectrum_table['flux'])  # normalized\n",
        "        flux_error = np.array(spectrum_table['flux_error'])\n",
        "\n",
        "        # Save to cache\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        np.savez(cache_file, wavelength=wavelength,\n",
        "                 flux=flux, flux_error=flux_error)\n",
        "\n",
        "        return wavelength, flux, flux_error\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading spectrum for source {source_id}: {e}\")\n",
        "        return None, None\n",
        "\n",
        "def download_multiple_spectra(sources, max_spectra=None):\n",
        "    if max_spectra is None:\n",
        "        max_spectra = len(sources)\n",
        "\n",
        "    spectra_data = {}\n",
        "    successful_downloads = 0\n",
        "\n",
        "    print(f\"\\nDownloading RVS spectra for up to {max_spectra} sources...\")\n",
        "\n",
        "    # Check column names (Gaia returns uppercase)\n",
        "    if 'SOURCE_ID' in sources.colnames:\n",
        "        source_id_col = 'SOURCE_ID'\n",
        "    else:\n",
        "        source_id_col = 'source_id'\n",
        "\n",
        "    for i, source in enumerate(sources[:max_spectra]):\n",
        "        source_id = source[source_id_col]\n",
        "\n",
        "        if i % 10 == 0:\n",
        "            print(f\"Progress: {i}/{max_spectra} spectra processed...\")\n",
        "\n",
        "        wavelength, flux, flux_error = download_rvs_spectrum(source_id)\n",
        "\n",
        "        if wavelength is not None and flux is not None:\n",
        "            spectra_data[source_id] = (wavelength, flux, flux_error)\n",
        "            successful_downloads += 1\n",
        "\n",
        "    print(f\"\\nSuccessfully downloaded {successful_downloads} spectra\")\n",
        "\n",
        "    return spectra_data\n",
        "\n",
        "def create_spectral_matrices(spectra_data, wavelength_grid=None, fill_value=1.0):\n",
        "    \"\"\"\n",
        "    Create a matrices Y, W where each row is a spectrum or its invvar weight\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    spectra_data : dict\n",
        "        Dictionary of (wavelength, flux) tuples\n",
        "    wavelength_grid : array-like, optional\n",
        "        Common wavelength grid. If None, uses the first spectrum's grid\n",
        "    fill_value : float\n",
        "        Value to use for replacing NaN/Inf (default: 1.0 for continuum)\n",
        "    n_clip_lower : int\n",
        "        Number of pixels to clip from the lower wavelength end\n",
        "    n_clip_upper : int\n",
        "        Number of pixels to clip from the upper wavelength end\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    Y : np.ndarray\n",
        "        Matrix of shape (n_spectra, n_wavelengths)\n",
        "    wavelength_grid : np.ndarray\n",
        "        Wavelength grid used\n",
        "    source_ids : list\n",
        "        List of source IDs in same order as rows of Y\n",
        "    W : np.ndarray\n",
        "        invvars for Y, with bad pixels zeroed out\n",
        "    \"\"\"\n",
        "\n",
        "    source_ids = list(spectra_data.keys())\n",
        "    n_spectra = len(source_ids)\n",
        "\n",
        "    # Use first spectrum to define wavelength grid if not provided\n",
        "    if wavelength_grid is None:\n",
        "        wavelength_grid = spectra_data[source_ids[0]][0]\n",
        "    n_wavelengths = len(wavelength_grid)\n",
        "\n",
        "    # Initialize spectral matrix and bad pixel mask\n",
        "    Y = np.zeros((n_spectra, n_wavelengths)) + np.nan\n",
        "    W = np.zeros((n_spectra, n_wavelengths))\n",
        "\n",
        "    # Track statistics\n",
        "    total_bad_pixels = 0\n",
        "    spectra_with_bad_pixels = 0\n",
        "\n",
        "    # Fill matrix\n",
        "    for i, source_id in enumerate(source_ids):\n",
        "        wavelength, flux, flux_error = spectra_data[source_id]\n",
        "\n",
        "        # Make weights / invvars\n",
        "        invvar = 1. / flux_error ** 2\n",
        "        bad_pixels = np.isnan(flux) | np.isinf(flux)\n",
        "        if np.any(bad_pixels):\n",
        "            spectra_with_bad_pixels += 1\n",
        "            total_bad_pixels += np.sum(bad_pixels)\n",
        "\n",
        "            # Replace bad pixels with fill_value\n",
        "            flux = np.where(bad_pixels, fill_value, flux)\n",
        "            invvar = np.where(bad_pixels, 0., invvar)\n",
        "\n",
        "        Y[i, :] = flux\n",
        "        W[i, :] = invvar\n",
        "\n",
        "    print(f\"\\nBad pixel statistics:\")\n",
        "    print(f\"  Spectra with bad pixels: {spectra_with_bad_pixels}/{n_spectra}\")\n",
        "    print(f\"  Total bad pixels: {total_bad_pixels}\")\n",
        "    print(f\"  Bad pixels replaced with: {fill_value}\")\n",
        "\n",
        "    return Y, wavelength_grid, source_ids, W\n"
      ],
      "metadata": {
        "id": "V79LEyhzSIkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spectra_data = download_multiple_spectra(sources, max_spectra=params['n_sources'])"
      ],
      "metadata": {
        "id": "MlynVJz1X4ai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y, wavelength_grid, source_ids, W = create_spectral_matrices(spectra_data)\n",
        "print(f\"Spectral matrix shape: {Y.shape}\")\n",
        "print(f\"Wavelength range: {wavelength_grid[0]:.2f} - {wavelength_grid[-1]:.2f} nm\")\n",
        "\n",
        "# Additional diagnostics\n",
        "print(f\"\\nSpectral matrix statistics:\")\n",
        "print(f\"  Min flux: {np.min(Y):.4f}\")\n",
        "print(f\"  Max flux: {np.max(Y):.4f}\")\n",
        "print(f\"  Mean flux: {np.mean(Y):.4f}\")\n",
        "print(f\"  Std flux: {np.std(Y):.4f}\")\n",
        "print(f\"  Mean invvar: {np.nanmean(W):.4f}\")\n",
        "print(f\"  Contains NaN: {np.any(np.isnan(Y))}\")\n",
        "print(f\"  Contains Inf: {np.any(np.isinf(Y))}\")"
      ],
      "metadata": {
        "id": "jyILviidYLiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RHMF():\n",
        "    def __init__(self, rank, nsigma):\n",
        "        self.K = int(rank)\n",
        "        self.nsigma = float(nsigma)\n",
        "        self.Q2 = self.nsigma ** 2\n",
        "\n",
        "    def fit(self, data, weights):\n",
        "        \"\"\"\n",
        "        # inputs:\n",
        "        `data`:     (N, M) array of observations.\n",
        "        `weights`:  units of (and equivalent to) inverse uncertainty variances.\n",
        "        \"\"\"\n",
        "        assert np.sum(jnp.isnan(data)) == 0\n",
        "        assert np.sum(jnp.isnan(weights)) == 0\n",
        "        self.Y = jnp.array(data)\n",
        "        self.input_W = jnp.array(weights)\n",
        "        assert self.Y.shape == self.input_W.shape\n",
        "        self.N, self.M = self.Y.shape\n",
        "        self.converged = False\n",
        "        self.n_iter = 0\n",
        "        self._initialize()\n",
        "        print(\"fit(): before starting:\", self.objective(), self.original_objective())\n",
        "        while not self.converged:\n",
        "            print(\"fit(): before A-step:\", self.objective(), self.original_objective())\n",
        "            self._A_step()\n",
        "            print(\"fit(): before G-step:\", self.objective(), self.original_objective())\n",
        "            self._G_step()\n",
        "            print(\"fit(): before affine step:\", self.objective(), self.original_objective())\n",
        "            self._affine()\n",
        "            print(\"fit(): before weight update step:\", self.objective(), self.original_objective())\n",
        "            self._update_W()\n",
        "            print(\"fit(): after weight update step:\", self.objective(), self.original_objective())\n",
        "            self.n_iter += 1\n",
        "\n",
        "    def _initialize(self):\n",
        "        \"\"\"\n",
        "        # bugs:\n",
        "        - Consider switching SVD to a fast PCA implementation?\n",
        "        \"\"\"\n",
        "        self.W = 1. * self.input_W # copy not reference\n",
        "        u, s, v = jnp.linalg.svd(Y, full_matrices=False) # maybe slow\n",
        "        self.A = (u[:,:self.K] * s[:self.K]).T\n",
        "        self.G = v[:self.K,:]\n",
        "        print(\"_initialize():\", self.A.shape, self.G.shape)\n",
        "\n",
        "    def _one_star_A_step(self, i):\n",
        "        XTCinvX = self.G * self.W[i] @ self.G.T\n",
        "        XTCinvY = self.G * self.W[i] @ self.Y[i]\n",
        "        return jnp.linalg.solve(XTCinvX, XTCinvY)\n",
        "\n",
        "    def _one_star_G_step(self, j):\n",
        "        XTCinvX = self.A * self.W[:,j] @ self.A.T\n",
        "        XTCinvY = self.A * self.W[:,j] @ self.Y[:,j]\n",
        "        return jnp.linalg.solve(XTCinvX, XTCinvY)\n",
        "\n",
        "    def _A_step(self):\n",
        "        self.A = jax.vmap(self._one_star_A_step)(jnp.arange(self.N)).T\n",
        "\n",
        "    def _G_step(self):\n",
        "        foo = self.objective()\n",
        "        self.G = jax.vmap(self._one_star_G_step)(jnp.arange(self.M)).T\n",
        "        bar = self.objective()\n",
        "        if foo < bar:\n",
        "            print(\"_G_step(): ERROR: objective got worse\", foo, bar)\n",
        "        if foo - bar < 1.e-2: # magic\n",
        "            self.converged = True\n",
        "\n",
        "    def _affine(self):\n",
        "        \"\"\"\n",
        "        # bugs:\n",
        "        - Consider switching SVD to a fast PCA implementation?\n",
        "        \"\"\"\n",
        "        u, s, v = jnp.linalg.svd(self.A.T @ self.G, full_matrices=False)\n",
        "        self.A = (u[:,:self.K] * s[:self.K]).T\n",
        "        self.G = v[:self.K,:]\n",
        "\n",
        "    def synthesis(self):\n",
        "        return self.A.T @ self.G\n",
        "\n",
        "    def resid(self):\n",
        "        return self.Y - self.synthesis()\n",
        "\n",
        "    def objective(self):\n",
        "        return jnp.sum(self.W * self.resid() ** 2)\n",
        "\n",
        "    def original_chi(self):\n",
        "        return self.resid() * jnp.sqrt(self.input_W)\n",
        "\n",
        "    def original_objective(self):\n",
        "        return jnp.sum(self.input_W * self.resid() ** 2)\n",
        "\n",
        "    def _update_W(self):\n",
        "        self.W = self.input_W * self.Q2 / (self.input_W * self.resid() ** 2 + self.Q2)"
      ],
      "metadata": {
        "id": "kILOH-tBtao-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RHMF(10, 2.5)\n",
        "model.fit(Y, W)"
      ],
      "metadata": {
        "id": "9kxBDYApYwL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k, g in enumerate(model.G):\n",
        "    plt.plot(wavelength_grid, g + 0.15 * k)"
      ],
      "metadata": {
        "id": "2BCii8esZsIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chi = model.original_chi()\n",
        "chi_squared = np.sum(chi ** 2, axis=1)\n",
        "indx = np.argsort(chi_squared)\n",
        "print(chi.shape, indx.shape)"
      ],
      "metadata": {
        "id": "lqNbmMVFbbbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resid = model.resid()\n",
        "for i in range(8):\n",
        "    plt.plot(wavelength_grid, resid[indx[-i]] + 0.03 * i)"
      ],
      "metadata": {
        "id": "jJVBUCQbcnn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qahI_xjbc3EA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}