{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ea1eada-579f-4edd-8b72-167b6d89643d",
   "metadata": {},
   "source": [
    "# Robust HMF on *BOSS* spectra of hot stars...\n",
    "...to find evidence of H-alpha emission.\n",
    "\n",
    "## Authors:\n",
    "- **David W. Hogg** (NYU) (MPIA) (Flatiron)\n",
    "- **Hans-Walter Rix** (MPIA)\n",
    "\n",
    "## To-do items:\n",
    "- Vet results and deliver to HWR's people.\n",
    "- Make some method (perhaps in `rhmf.py`) to save and restore a Robust HMF model.\n",
    "\n",
    "## Bugs:\n",
    "- Probably RHMF is the wrong tool for this job?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dda567f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.io import fits\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import os\n",
    "import concurrent.futures\n",
    "import matplotlib.pyplot as plt\n",
    "import rhmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c5e629-4385-4bc5-9e54-f322c7bed0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data choices\n",
    "bosstag = 'v6_2_1'\n",
    "cachedir = f'./boss_{bosstag}_star_cache'\n",
    "os.makedirs(cachedir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ff5044-fdf2-454a-a415-3222f084107f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model choices\n",
    "rank, nsigma = 24, 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6644a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define download functions\n",
    "user, password = None, None\n",
    "\n",
    "def download_one_file_from_df(args):\n",
    "    \"\"\"Download a single file from SDSS.\"\"\"\n",
    "    url, filename, user, password, cachedir = args\n",
    "    filepath = os.path.join(cachedir, filename)\n",
    "    \n",
    "    # Skip if already downloaded\n",
    "    if os.path.exists(filepath):\n",
    "        # print(f\"File {filename} already exists, skipping\")\n",
    "        return True\n",
    "        \n",
    "    try:\n",
    "        with requests.Session() as session:\n",
    "            response = session.get(url, auth=HTTPBasicAuth(user, password), timeout=30)\n",
    "            response.raise_for_status()\n",
    "            with open(filepath, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "        if np.random.uniform() < 0.1:\n",
    "            print(f\"Random example: File downloaded: {filename}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download {filename}: {e}\")\n",
    "        return False\n",
    "\n",
    "def download_files_from_df(df, user, password, dest_folder, boss_tag='v6_2_1', coadd_version='daily', max_workers=8):\n",
    "    \"\"\"Download multiple files from SDSS based on dataframe.\"\"\"\n",
    "    os.makedirs(dest_folder, exist_ok=True)\n",
    "    args_list = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        spec_file = row['SPEC_FILE']\n",
    "        fieldid = f\"{row['FIELD']:06d}\"\n",
    "        mjd = str(row['MJD'])\n",
    "        fieldidXXX = fieldid[:-3] + 'XXX'\n",
    "        url = (\n",
    "            f\"https://data.sdss5.org/sas/sdsswork/bhm/boss/spectro/redux/\"\n",
    "            f\"{boss_tag}/spectra/{coadd_version}/lite/{fieldidXXX}/{fieldid}/{mjd}/{spec_file}\"\n",
    "        )\n",
    "        args_list.append((url, spec_file, user, password, dest_folder))\n",
    "\n",
    "    print(f\"Starting attempts to download {len(args_list)} files\")\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        results = list(executor.map(download_one_file_from_df, args_list))\n",
    "    print(f\"Number successful: {sum(results)} files\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba33d8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and examine the summary file\n",
    "spallname = f'spAll-lite-{bosstag}.fits'\n",
    "summaryurl = f'https://data.sdss5.org/sas/sdsswork/bhm/boss/spectro/redux/{bosstag}/summary/daily/{spallname}.gz'\n",
    "summaryfile = cachedir + '/' + spallname + '.gz'\n",
    "summaryfile_uncompressed = cachedir + '/' + spallname\n",
    "\n",
    "if not os.path.exists(summaryfile_uncompressed):\n",
    "    if not os.path.exists(summaryfile):\n",
    "        print(f\"Downloading summary file from {summaryurl}\")\n",
    "        response = requests.get(summaryurl, auth=HTTPBasicAuth(user, password))\n",
    "        with open(summary_file, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"Summary file {summaryfile} downloaded\")\n",
    "    \n",
    "    # Decompress\n",
    "    os.system(f'gunzip -v {summaryfile}')\n",
    "    print(f\"Summary file {summaryfile} decompressed\")\n",
    "else:\n",
    "    print(f\"Summary file {summaryfile_uncompressed} already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb33fe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load summary data\n",
    "with fits.open(summaryfile_uncompressed) as hdul:\n",
    "    data = hdul[1].data\n",
    "\n",
    "if False:\n",
    "    print(\"=\"*70)\n",
    "    print(\"ALL AVAILABLE COLUMNS IN SUMMARY FILE\")\n",
    "    print(\"=\"*70)\n",
    "    columns = data.columns.names\n",
    "    for i, col in enumerate(columns):\n",
    "        print(f\"{i+1:3d}. {col}\")\n",
    "\n",
    "print(f\"rows: {len(data)}; columns: {len(data.columns.names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ddad07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a sample of spectra to download\n",
    "# Let's look for high-SNR spectra with BP_MAG - RP_MAG < 0.5 to examine\n",
    "df = pd.DataFrame({col: data[col].byteswap().newbyteorder() for col in ['SPEC_FILE', 'FIELD', 'MJD', 'SN_MEDIAN_ALL', 'BP_MAG', 'RP_MAG', 'PROGRAMNAME']})\n",
    "\n",
    "# Filter for high SNR and BP_MAG - RP_MAG < 0.5 spectra\n",
    "high_snr_df = df[(df['SN_MEDIAN_ALL'] > 40) & (df['PROGRAMNAME'] == 'mwm_ob') ] #.head(50)  # Just 50 spectra for testing\n",
    "print(f\"Selected {len(high_snr_df)} high-SNR and BP-RP < 0.5 spectra for header examination\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164f6093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the sample spectra\n",
    "_ = download_files_from_df(high_snr_df, user, password, cachedir, boss_tag=bosstag, coadd_version='daily', max_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4236423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the headers of downloaded spectra\n",
    "if False:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"EXAMINING SPECTRA HEADERS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    spec_files = [f for f in os.listdir(cachedir) if f.endswith('.fits')][:3]  # Examine first 3\n",
    "    \n",
    "    for i, spec_file in enumerate(spec_files):\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"SPECTRUM {i+1}: {spec_file}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        filepath = os.path.join(cachedir, spec_file)\n",
    "        with fits.open(filepath) as hdul:\n",
    "            print(f\"\\nNumber of HDUs: {len(hdul)}\")\n",
    "            \n",
    "            for j, hdu in enumerate(hdul):\n",
    "                print(f\"\\n--- HDU {j}: {type(hdu).__name__} ---\")\n",
    "                \n",
    "                # Print header info\n",
    "                if hdu.header:\n",
    "                    print(f\"Header cards: {len(hdu.header)} cards\")\n",
    "                    print(\"\\nFirst 20 header keywords:\")\n",
    "                    for k, (key, value) in enumerate(list(hdu.header.items())[:20]):\n",
    "                        print(f\"  {key:8s} = {str(value)[:60]}\")\n",
    "                    if len(hdu.header) > 20:\n",
    "                        print(f\"  ... and {len(hdu.header)-20} more header cards\")\n",
    "                \n",
    "                # If it's a table, show columns\n",
    "                if hasattr(hdu, 'columns'):\n",
    "                    print(f\"\\nTable columns: {len(hdu.columns)}\")\n",
    "                    for col in hdu.columns:\n",
    "                        print(f\"  - {col.name:20s} ({col.format})\")\n",
    "                \n",
    "                # If it's image data, show shape\n",
    "                if hasattr(hdu, 'data') and hdu.data is not None:\n",
    "                    if isinstance(hdu, fits.PrimaryHDU) or isinstance(hdu, fits.ImageHDU):\n",
    "                        print(f\"\\nImage data shape: {hdu.data.shape}\")\n",
    "                    elif isinstance(hdu, fits.BinTableHDU):\n",
    "                        print(f\"\\nTable rows: {len(hdu.data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea5da0b-8b60-47d4-ac27-82db13834362",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_one_spectrum(wavelength, flux, ivar, name, prefix, synth=None):\n",
    "    f = plt.figure(figsize=(12, 4))\n",
    "    plt.axhline(0., lw=0.5, color='k', alpha=0.45)\n",
    "    plt.step(wavelength, flux,\n",
    "             where='mid', color='k', lw=0.5, alpha=0.90)\n",
    "    tiny = 0.01 / np.median(flux) ** 2\n",
    "    flhi = flux + 1. / np.sqrt(ivar + tiny)\n",
    "    fllo = flux - 1. / np.sqrt(ivar + tiny)\n",
    "    plt.fill_between(wavelength, fllo, flhi,\n",
    "                     step='mid', color='k', alpha=0.23)\n",
    "    if synth is not None:\n",
    "        plt.step(wavelength, flux - synth,\n",
    "                 where='mid', color='k', lw=0.5, alpha=0.90)\n",
    "        plt.step(wavelength, synth,\n",
    "                 where='mid', color='r', lw=0.5, alpha=0.90)\n",
    "        plt.step(wavelength, np.zeros_like(flux),\n",
    "                 where='mid', color='r', lw=0.5, alpha=0.90)\n",
    "    plt.xticks([2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000])\n",
    "    plt.xlim(np.min(wavelength), np.max(wavelength))\n",
    "    foo = np.nanmedian(flux)\n",
    "    plt.ylim(-0.5 * foo, 2.5 * foo)\n",
    "    plt.semilogx()\n",
    "    plt.xlabel('wavelength')\n",
    "    plt.ylabel('flux')\n",
    "    plt.title(name)\n",
    "    \n",
    "    # Save plot\n",
    "    plot_filename = plot_folder + '/' + prefix + name + '.png'\n",
    "    plt.savefig(plot_filename)\n",
    "    plt.close(f)\n",
    "    print(f\"  Plot saved: {plot_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5828a77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subdirectory for plots\n",
    "plot_folder = cachedir + '/plots'\n",
    "os.makedirs(plot_folder, exist_ok=True)\n",
    "\n",
    "# Get list of downloaded FITS files (up to Nmax)\n",
    "Nmax = 10\n",
    "spec_files = [f for f in os.listdir(cachedir) if f.endswith('.fits')][:Nmax]\n",
    "print(f\"Found {len(spec_files)} spectra to plot (limited to {Nmax})\")\n",
    "\n",
    "for i, spec_file in enumerate(spec_files):\n",
    "    filepath = cachedir + \"/\" + spec_file\n",
    "\n",
    "    with fits.open(filepath) as hdul:\n",
    "        if len(hdul) > 1 and hasattr(hdul[1], 'data'):\n",
    "            spec_data = hdul[1].data\n",
    "            loglam = spec_data['LOGLAM']\n",
    "            flux = spec_data['FLUX']\n",
    "            ivar = spec_data['IVAR']\n",
    "            wavelength = 10**loglam\n",
    "            plot_one_spectrum(wavelength, flux, ivar, spec_file, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0e867e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a data block\n",
    "print(\"assembling file names for reading\")\n",
    "filenames = np.array([f for f in os.listdir(cachedir) if f.endswith('.fits') and f.startswith('spec-')])\n",
    "wavelength = None\n",
    "N = len(filenames)\n",
    "print(f\"reading {N} files...\")\n",
    "for i, fn in enumerate(filenames):\n",
    "    filepath = cachedir + '/' + fn\n",
    "    \n",
    "    try:\n",
    "        with fits.open(filepath) as hdul:\n",
    "            if len(hdul) > 1 and hasattr(hdul[1], 'data'):\n",
    "                spec_data = hdul[1].data\n",
    "                loglam = spec_data['LOGLAM']\n",
    "                fl = spec_data['FLUX']\n",
    "                iv = spec_data['IVAR']\n",
    "                wa = 10**loglam\n",
    "                if wavelength is None:\n",
    "                    wavelength = wa\n",
    "                    M = len(wavelength)\n",
    "                    flux = np.ones((N, M))\n",
    "                    ivar = np.zeros_like(flux)\n",
    "                if np.allclose(wa, wavelength):\n",
    "                    flux[i] = fl / np.median(fl)\n",
    "                    ivar[i] = iv * np.median(fl) ** 2\n",
    "                else:\n",
    "                    print(f\"  Dropped {filepath}: bad wavelength grid\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  Dropped {filepath}: {e}\")\n",
    "\n",
    "print(\"data blocks:\", flux.shape, ivar.shape, np.prod(flux.shape))\n",
    "print(\"bad pixels:\", np.sum(~ np.isfinite(flux)), np.sum(~ np.isfinite(ivar)),\n",
    "      np.sum(ivar <= 0.) / np.prod(flux.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ca7d3e-0d8f-4347-8ca2-8a39c6056421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim data\n",
    "good = (wavelength > 3700.) # magic\n",
    "wavelength = wavelength[good]\n",
    "flux = flux[:, good]\n",
    "ivar = ivar[:, good]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ce1261-6f4e-4c2d-a17c-9a549b4ccd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# floor and ceil the ivars ## HACK\n",
    "maxivar = 1.e4 / flux ** 2 # magic -- nothing is known to better than 1 percent\n",
    "ivar = np.clip(ivar, 0., maxivar)\n",
    "maxivar = 1.e4 / np.median(flux, axis=1) ** 2 # magic -- nothing is known to better than 1 percent on average\n",
    "minivar = 1.e-2 / np.median(flux, axis=1) ** 2 # magic -- there is some information even at useless pixels\n",
    "ivar = np.clip(ivar, minivar[:, None], maxivar[:, None])\n",
    "print(np.min(ivar), np.max(ivar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da651bcd-9d85-4e36-b955-21e21af09cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make two disjoint training sets\n",
    "N, M = flux.shape\n",
    "rng = np.random.default_rng(17)\n",
    "foo = np.random.uniform(size=N)\n",
    "A = foo < np.median(foo)\n",
    "B = np.logical_not(A)\n",
    "print(np.sum(A), np.sum(B), ~np.any(np.logical_and(A, B)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33901f65-2d36-4533-af94-c4d093b62e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Aidx = np.arange(N)[A]\n",
    "Bidx = np.arange(N)[B]\n",
    "print(len(Aidx), len(Bidx), np.all(A[Aidx]), np.all(B[Bidx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfda24e3-3689-4fd4-a21b-e5158596283a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_G(model, title):\n",
    "    plt.figure(figsize=(12,8))\n",
    "    for k, g in enumerate(model.G):\n",
    "        plt.step(wavelength, 10. * g + k,\n",
    "                 where='mid', lw=0.5, alpha=0.90)\n",
    "    plt.xlabel(\"wavelength\")\n",
    "    plt.xlim(np.min(wavelength), np.max(wavelength))\n",
    "    plt.semilogx()\n",
    "    plt.ylim(-1., model.K)\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f40285-387b-4cc5-8e2f-880bab46b17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_test(Y, W, models):\n",
    "    assert len(models) == 2\n",
    "    synth = np.zeros_like(flux) + np.nan\n",
    "    print(np.sum(np.isnan(synth)))\n",
    "    for m in range(2):\n",
    "        n = (m + 1) % 2\n",
    "        model, _, _ = models[m]\n",
    "        _, idx, _ = models[n]\n",
    "        for i in idx:\n",
    "            synth[i] = model.test(Y[i], W[i])\n",
    "        print(np.sum(np.isnan(synth)))    \n",
    "    return synth\n",
    "\n",
    "def train_and_test(Y, W, models, maxiter=10):\n",
    "    for model, idx, label in models:\n",
    "        print(label)\n",
    "        model.train(Y[idx], W[idx], maxiter=maxiter)\n",
    "        plot_G(model, label)\n",
    "        plt.show()\n",
    "    synth = cross_test(Y, W, models)\n",
    "    for i in range(100):\n",
    "        plot_one_spectrum(wavelength, Y[i], W[i], filenames[i], \"\", synth=synth[i])\n",
    "    return synth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51526b4c-9e71-425a-8475-9643d553f8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start models\n",
    "models = [(rhmf.RHMF(rank, nsigma), Aidx, \"model A\"),\n",
    "          (rhmf.RHMF(rank, nsigma), Bidx, \"model B\")]\n",
    "synth = train_and_test(flux, ivar, models, maxiter=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bb2643-20b8-4637-89cc-8d62f7d83e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train more\n",
    "synth = train_and_test(flux, ivar, models, maxiter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce75d5d-1fc2-40fd-88a1-6d257b2a7594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train even more\n",
    "synth = train_and_test(flux, ivar, models, maxiter=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9574d9b2-25b0-4063-aae2-09d350599c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now re-run the test step but with the H-alpha region censored.\n",
    "halpha = 6564.6\n",
    "delta = 6. # magic\n",
    "near_halpha = (wavelength > (halpha - delta)) & (wavelength < (halpha + delta))\n",
    "print(np.sum(near_halpha))\n",
    "ivar_halpha = 1. * ivar # copy\n",
    "ivar_halpha[:, near_halpha] = 0.\n",
    "synth_halpha = cross_test(flux, ivar_halpha, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e78b33-444c-4b39-97b8-9394c59c4efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now order the results by the significance of the H-alpha region deviation (chi)\n",
    "resid = flux - synth_halpha\n",
    "chi_halpha = (resid * np.sqrt(ivar))[:, near_halpha]\n",
    "print(chi_halpha.shape)\n",
    "chi2_halpha = np.sum(chi_halpha ** 2, axis=1)\n",
    "interesting = np.argsort(-chi2_halpha)\n",
    "_ = plt.hist(np.log10(chi2_halpha), bins=100)\n",
    "plt.xlabel(\"log10(chi-squared)\")\n",
    "plt.semilogy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55725daf-89dd-4a07-8e11-31078d024611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the best candidates for delivery to our people\n",
    "for i in interesting[:200]:\n",
    "    plot_one_spectrum(wavelength, flux[i], ivar[i], filenames[i], \"halpha-\", synth=synth_halpha[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d86a03b-e5b5-4093-b63b-b41ed07bf5f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
