{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ea1eada-579f-4edd-8b72-167b6d89643d",
   "metadata": {},
   "source": [
    "# Robust HMF on *BOSS* spectra of hot stars...\n",
    "...to find evidence of H-alpha emission.\n",
    "\n",
    "## Authors:\n",
    "- **David W. Hogg** (NYU) (MPIA) (Flatiron)\n",
    "- **Hans-Walter Rix** (MPIA)\n",
    "\n",
    "## To-do items:\n",
    "- Vet results and deliver to HWR's people.\n",
    "- Make some method (perhaps in `rhmf.py`) to save and restore a Robust HMF model.\n",
    "\n",
    "## Bugs:\n",
    "- Probably RHMF is the wrong tool for this job?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dda567f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.io import fits\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import os\n",
    "import concurrent.futures\n",
    "import matplotlib.pyplot as plt\n",
    "import rhmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c5e629-4385-4bc5-9e54-f322c7bed0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data choices\n",
    "bosstag = 'v6_2_1'\n",
    "cachedir = f'./boss_{bosstag}_star_cache'\n",
    "os.makedirs(cachedir, exist_ok=True)\n",
    "\n",
    "# Create subdirectory for plots\n",
    "plot_folder = cachedir + '/plots'\n",
    "os.makedirs(plot_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ff5044-fdf2-454a-a415-3222f084107f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model choices\n",
    "rank, nsigma = 24, 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6644a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define download functions\n",
    "user, password = None, None\n",
    "\n",
    "def download_one_file_from_df(args):\n",
    "    \"\"\"Download a single file from SDSS.\"\"\"\n",
    "    url, filename, user, password, cachedir = args\n",
    "    filepath = os.path.join(cachedir, filename)\n",
    "    \n",
    "    # Skip if already downloaded\n",
    "    if os.path.exists(filepath):\n",
    "        # print(f\"File {filename} already exists, skipping\")\n",
    "        return True\n",
    "        \n",
    "    try:\n",
    "        with requests.Session() as session:\n",
    "            response = session.get(url, auth=HTTPBasicAuth(user, password), timeout=30)\n",
    "            response.raise_for_status()\n",
    "            with open(filepath, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "        if np.random.uniform() < 0.1:\n",
    "            print(f\"Random example: File downloaded: {filename}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download {filename}: {e}\")\n",
    "        return False\n",
    "\n",
    "def download_files_from_df(df, user, password, dest_folder, boss_tag='v6_2_1', coadd_version='daily', max_workers=8):\n",
    "    \"\"\"Download multiple files from SDSS based on dataframe.\"\"\"\n",
    "    os.makedirs(dest_folder, exist_ok=True)\n",
    "    args_list = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        spec_file = row['SPEC_FILE']\n",
    "        fieldid = f\"{row['FIELD']:06d}\"\n",
    "        mjd = str(row['MJD'])\n",
    "        fieldidXXX = fieldid[:-3] + 'XXX'\n",
    "        url = (\n",
    "            f\"https://data.sdss5.org/sas/sdsswork/bhm/boss/spectro/redux/\"\n",
    "            f\"{boss_tag}/spectra/{coadd_version}/lite/{fieldidXXX}/{fieldid}/{mjd}/{spec_file}\"\n",
    "        )\n",
    "        args_list.append((url, spec_file, user, password, dest_folder))\n",
    "\n",
    "    print(f\"Starting attempts to download {len(args_list)} files\")\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        results = list(executor.map(download_one_file_from_df, args_list))\n",
    "    print(f\"Number successful: {sum(results)} files\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba33d8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and examine the spAll file\n",
    "spallname = f'spAll-lite-{bosstag}.fits'\n",
    "summaryurl = f'https://data.sdss5.org/sas/sdsswork/bhm/boss/spectro/redux/{bosstag}/summary/daily/{spallname}.gz'\n",
    "summaryfile = cachedir + '/' + spallname + '.gz'\n",
    "summaryfile_uncompressed = cachedir + '/' + spallname\n",
    "\n",
    "if not os.path.exists(summaryfile_uncompressed):\n",
    "    if not os.path.exists(summaryfile):\n",
    "        print(f\"Downloading summary file from {summaryurl}\")\n",
    "        response = requests.get(summaryurl, auth=HTTPBasicAuth(user, password))\n",
    "        with open(summary_file, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"Summary file {summaryfile} downloaded\")\n",
    "    \n",
    "    # Decompress\n",
    "    os.system(f'gunzip -v {summaryfile}')\n",
    "    print(f\"Summary file {summaryfile} decompressed\")\n",
    "else:\n",
    "    print(f\"Summary file {summaryfile_uncompressed} already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb33fe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spAll data\n",
    "with fits.open(summaryfile_uncompressed) as hdul:\n",
    "    data = hdul[1].data\n",
    "if False:\n",
    "    print(\"=\"*70)\n",
    "    print(\"ALL AVAILABLE COLUMNS IN SUMMARY FILE\")\n",
    "    print(\"=\"*70)\n",
    "    columns = data.columns.names\n",
    "    for i, col in enumerate(columns):\n",
    "        print(f\"{i+1:3d}. {col}\")\n",
    "print(f\"rows: {len(data)}; columns: {len(data.columns.names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ddad07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a sample of spectra to download\n",
    "# Let's look for high-SNR spectra with BP_MAG - RP_MAG < 0.5 to examine\n",
    "df = pd.DataFrame({col: data[col].byteswap().newbyteorder() for col in ['SPEC_FILE', 'FIELD', 'MJD', 'SN_MEDIAN_ALL', 'BP_MAG', 'RP_MAG', 'PROGRAMNAME']})\n",
    "\n",
    "# Filter for high SNR and BP_MAG - RP_MAG < 0.5 spectra\n",
    "high_snr_df = df[(df['SN_MEDIAN_ALL'] > 40) & (df['PROGRAMNAME'] == 'mwm_ob') ] #.head(50)  # Just 50 spectra for testing\n",
    "print(f\"Selected {len(high_snr_df)} high-SNR and BP-RP < 0.5 spectra for header examination\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164f6093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the sample spectra\n",
    "_ = download_files_from_df(high_snr_df, user, password, cachedir, boss_tag=bosstag, coadd_version='daily', max_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2aeeef-3e19-4253-8865-37d5301b4e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make lists of strings\n",
    "filenames = np.array([f for f in os.listdir(cachedir) if f.endswith('.fits') and f.startswith('spec-')])\n",
    "starnames = np.array([f[5:-5] for f in filenames])\n",
    "print(filenames.shape, starnames.shape, filenames[13], starnames[13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0e867e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make rectangular data, plus wavelength grid\n",
    "wavelength = None\n",
    "N = len(filenames)\n",
    "print(f\"reading {N} files...\")\n",
    "for i, fn in enumerate(filenames):\n",
    "    filepath = cachedir + '/' + fn\n",
    "    \n",
    "    try:\n",
    "        with fits.open(filepath) as hdul:\n",
    "            if len(hdul) > 1 and hasattr(hdul[1], 'data'):\n",
    "                spec_data = hdul[1].data\n",
    "                loglam = spec_data['LOGLAM']\n",
    "                fl = spec_data['FLUX']\n",
    "                iv = spec_data['IVAR']\n",
    "                wa = 10**loglam\n",
    "                if wavelength is None:\n",
    "                    wavelength = wa\n",
    "                    M = len(wavelength)\n",
    "                    flux = np.ones((N, M))\n",
    "                    ivar = np.zeros_like(flux)\n",
    "                if np.allclose(wa, wavelength):\n",
    "                    flux[i] = fl / np.median(fl)\n",
    "                    ivar[i] = iv * np.median(fl) ** 2\n",
    "                else:\n",
    "                    print(f\"  Dropped {filepath}: bad wavelength grid\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  Dropped {filepath}: {e}\")\n",
    "\n",
    "print(\"data blocks:\", flux.shape, ivar.shape, np.prod(flux.shape))\n",
    "print(\"bad pixels:\", np.sum(~ np.isfinite(flux)), np.sum(~ np.isfinite(ivar)),\n",
    "      np.sum(ivar <= 0.) / np.prod(flux.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ca7d3e-0d8f-4347-8ca2-8a39c6056421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim data\n",
    "good = (wavelength > 3700) & (wavelength < 12000) # magic\n",
    "wavelength = wavelength[good]\n",
    "flux = flux[:, good]\n",
    "ivar = ivar[:, good]\n",
    "print(flux.shape, ivar.shape, wavelength.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ce1261-6f4e-4c2d-a17c-9a549b4ccd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# floor and ceil the ivars ## HACK\n",
    "maxivar = 1.e4 / flux ** 2 # magic -- nothing is known to better than 1 percent\n",
    "ivar = np.clip(ivar, 0., maxivar)\n",
    "maxivar = 1.e4 / np.median(flux, axis=1) ** 2 # magic -- nothing is known to better than 1 percent on average\n",
    "minivar = 1.e-4 / np.median(flux, axis=1) ** 2 # magic -- there is trivial information even at useless pixels\n",
    "ivar = np.clip(ivar, minivar[:, None], maxivar[:, None])\n",
    "print(np.min(ivar), np.max(ivar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da651bcd-9d85-4e36-b955-21e21af09cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make two disjoint training sets\n",
    "N, M = flux.shape\n",
    "rng = np.random.default_rng(17)\n",
    "foo = np.random.uniform(size=N)\n",
    "A = foo < np.median(foo)\n",
    "B = np.logical_not(A)\n",
    "print(np.sum(A), np.sum(B), ~np.any(np.logical_and(A, B)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33901f65-2d36-4533-af94-c4d093b62e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Aidx = np.arange(N)[A]\n",
    "Bidx = np.arange(N)[B]\n",
    "print(len(Aidx), len(Bidx), np.all(A[Aidx]), np.all(B[Bidx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d08f864-5660-4e32-a8bc-9bf2781b554f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting utility: Hydrogen recombination lines\n",
    "\n",
    "def hydrogen_line(n_upper, n_lower):\n",
    "    R_H = 10973731.568157 # (12) per meter; Wikipedia\n",
    "    wave_number = R_H * (1/n_lower**2 - 1/n_upper**2) # per meter\n",
    "    return (1. / np.abs(wave_number)) * 1.e10 # Angstrom\n",
    "\n",
    "def plot_hydrogen_lines(ax):\n",
    "    for n1 in (2, 3):\n",
    "        for n2 in range(n1 + 1, n1 + 15): # magic 15\n",
    "            ax.axvline(hydrogen_line(n2, n1), color=\"b\", lw=0.5, alpha=0.23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441df86a-05e2-423a-8821-368f529b4ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting utility: Hogg cares about wavelength axes.\n",
    "\n",
    "def hogg_wavelength_axis(ax, wavelength):\n",
    "    plot_hydrogen_lines(ax)\n",
    "    ax.semilogx()\n",
    "    ticks = [3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000]\n",
    "    ticklabels = [str(tick) for tick in ticks]\n",
    "    ax.set_xticks(ticks, ticklabels)\n",
    "    ax.set_xlim(np.min(wavelength), np.max(wavelength))\n",
    "    ax.set_xlabel('wavelength')\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfda24e3-3689-4fd4-a21b-e5158596283a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the eigenvectors of a model\n",
    "\n",
    "def plot_G(model, title):\n",
    "    plt.figure(figsize=(12,8))\n",
    "    for k, g in enumerate(model.G):\n",
    "        plt.step(wavelength, 10. * g + k,\n",
    "                 where='mid', lw=0.5, alpha=0.90)\n",
    "    plt.ylim(-1., model.K)\n",
    "    ax = hogg_wavelength_axis(plt.gca(), wavelength)\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea5da0b-8b60-47d4-ac27-82db13834362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a spectrum and a synthetic spectrum and residuals\n",
    "\n",
    "def plot_one_spectrum(wavelength, flux, ivar, name, prefix, synth=None):\n",
    "    f = plt.figure(figsize=(12, 4))\n",
    "    plt.axhline(0., lw=0.5, color='k', alpha=0.45)\n",
    "    plt.step(wavelength, flux,\n",
    "             where='mid', color='k', lw=0.5, alpha=0.90)\n",
    "    tiny = 0.01 / np.median(flux) ** 2\n",
    "    flhi = flux + 1. / np.sqrt(ivar + tiny)\n",
    "    fllo = flux - 1. / np.sqrt(ivar + tiny)\n",
    "    plt.fill_between(wavelength, fllo, flhi,\n",
    "                     step='mid', color='k', alpha=0.23)\n",
    "    if synth is not None:\n",
    "        plt.step(wavelength, flux - synth,\n",
    "                 where='mid', color='k', lw=0.5, alpha=0.90)\n",
    "        plt.step(wavelength, synth,\n",
    "                 where='mid', color='r', lw=0.5, alpha=0.90)\n",
    "        plt.step(wavelength, np.zeros_like(flux),\n",
    "                 where='mid', color='r', lw=0.5, alpha=0.90)\n",
    "\n",
    "    # adjust axes\n",
    "    foo = np.nanmedian(flux)\n",
    "    plt.ylim(-0.5 * foo, 2.5 * foo)\n",
    "    plt.ylabel('flux')\n",
    "    plt.title(name)\n",
    "    hogg_wavelength_axis(plt.gca(), wavelength)\n",
    "\n",
    "    # Save plot\n",
    "    plot_filename = plot_folder + '/' + prefix + name + '.png'\n",
    "    plt.savefig(plot_filename)\n",
    "    plt.close(f)\n",
    "    print(f\"  Plot saved: {plot_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc9fb48-ddab-49ea-9010-4f833c21d8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make test step but with a line held out of the fitting (like, say, H-alpha)\n",
    "\n",
    "def censored_cross_test(Y, W, models, line, delta):\n",
    "    near_line = (wavelength > (line - delta)) & (wavelength < (line + delta))\n",
    "    print(np.sum(near_line))\n",
    "    W_line = 1. * W # copy\n",
    "    W_line[:, near_line] = 0.\n",
    "    return cross_test(Y, W_line, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f40285-387b-4cc5-8e2f-880bab46b17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross test: Test A objects with model B, and B objects with model A.\n",
    "\n",
    "def cross_test(Y, W, models):\n",
    "    assert len(models) == 2\n",
    "    synth = np.zeros_like(Y) + np.nan\n",
    "    print(np.sum(np.isnan(synth)))\n",
    "    for m in range(2):\n",
    "        n = (m + 1) % 2\n",
    "        model, _, _ = models[m]\n",
    "        _, idx, _ = models[n]\n",
    "        for i in idx:\n",
    "            synth[i] = model.test(Y[i], W[i])\n",
    "        print(np.sum(np.isnan(synth)))    \n",
    "    return synth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d35616-6575-4a2c-958f-452ead237a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the full train and test pipeline\n",
    "\n",
    "def train_and_test(Y, W, models, maxiter=10):\n",
    "\n",
    "    # train step\n",
    "    for model, idx, label in models:\n",
    "        print(label)\n",
    "        model.train(Y[idx], W[idx], maxiter=maxiter)\n",
    "        plot_G(model, label)\n",
    "        plt.show()\n",
    "\n",
    "    # test step\n",
    "    halpha, delta = 6564.6, 5. # line from Wikipedia, Angstroms; delta from magic\n",
    "    synth_ex_halpha = censored_cross_test(Y, W, models, halpha, delta)\n",
    "\n",
    "    # choose interesting objects to plot\n",
    "    near_halpha = (wavelength > (halpha - delta)) & (wavelength < (halpha + delta))\n",
    "    resid = Y - synth_ex_halpha\n",
    "    chi_halpha = (resid * np.sqrt(W))[:, near_halpha]\n",
    "    chi2_halpha = np.sum(chi_halpha ** 2, axis=1)\n",
    "    interesting = np.argsort(-chi2_halpha)\n",
    "    _ = plt.hist(np.log10(chi2_halpha), bins=100)\n",
    "    plt.xlabel(\"log10(chi-squared)\")\n",
    "    plt.semilogy()\n",
    "    plt.show()\n",
    "\n",
    "    # make plots\n",
    "    prefix = \"halpha_emitter_\"\n",
    "    os.system(f\"rm -v {plot_folder}/{prefix}*.png\")\n",
    "    for i in interesting[:300]:\n",
    "        plot_one_spectrum(wavelength, Y[i], W[i], starnames[i], prefix, synth=synth_ex_halpha[i])\n",
    "    return synth_ex_halpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51526b4c-9e71-425a-8475-9643d553f8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start models\n",
    "models = [(rhmf.RHMF(rank, nsigma), Aidx, \"model A\"),\n",
    "          (rhmf.RHMF(rank, nsigma), Bidx, \"model B\")]\n",
    "synth = train_and_test(flux, ivar, models, maxiter=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce75d5d-1fc2-40fd-88a1-6d257b2a7594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train even more\n",
    "for t in range(30):\n",
    "    synth = train_and_test(flux, ivar, models, maxiter=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2121d8d1-027c-4f4b-9ae3-7d13213fc94b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
