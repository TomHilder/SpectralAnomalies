{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oai5DwmLtA-H"
   },
   "source": [
    "# Robust Heteroskedastic Matrix Factorization\n",
    "A robust-PCA-like model that knows about observational uncertainties\n",
    "\n",
    "## Author:\n",
    "- **David W. Hogg** (NYU) (MPIA) (Flatiron)\n",
    "- (with help from Claude)\n",
    "\n",
    "## Dependencies:\n",
    "- `pip3 install jax matplotlib astropy astroquery`\n",
    "\n",
    "## Issues:\n",
    "- Assumes (and gets) rectangular data with known uncertainties.\n",
    "- `train()` function is written but `test()` function is not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PheEt-VFs-cP"
   },
   "outputs": [],
   "source": [
    "# jax related\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "jax.config.update(\"jax_enable_x64\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PNHWYTqOT0gH"
   },
   "outputs": [],
   "source": [
    "# data-gathering and plotting related\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import clod\n",
    "plt.rcParams['figure.figsize'] = (8, 4.5)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uz35ejRgXYIy"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'teff_min': 8000,\n",
    "    'teff_max': 20000,\n",
    "    'logg_min': 1.0,\n",
    "    'logg_max': 5.0,\n",
    "    'grvs_mag_max': 9.0,\n",
    "    'n_sources': 500\n",
    "}\n",
    "sources = clod.find_rvs_sources_gspphot(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MlynVJz1X4ai"
   },
   "outputs": [],
   "source": [
    "n_sources = min(params['n_sources'], len(sources))\n",
    "spectra_data = clod.download_multiple_spectra(sources, max_spectra=n_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jyILviidYLiw"
   },
   "outputs": [],
   "source": [
    "Y, wavelength_grid, source_ids, W = clod.create_spectral_matrices(spectra_data)\n",
    "print(f\"\\nSpectral matrix statistics:\")\n",
    "print(f\"  shape: {Y.shape}\")\n",
    "print(f\"  min flux: {np.min(Y):.4f}\")\n",
    "print(f\"  max flux: {np.max(Y):.4f}\")\n",
    "print(f\"  mean flux: {np.mean(Y):.4f}\")\n",
    "print(f\"  std flux: {np.std(Y):.4f}\")\n",
    "print(f\"  median uncertainty: {1. / np.sqrt(np.median(W)):.4f}\")\n",
    "print(f\"  flux contains NaN: {np.any(np.isnan(Y))}\")\n",
    "print(f\"  flux contains Inf: {np.any(np.isinf(Y))}\")\n",
    "print(f\"  invvar zeros: {np.sum(W < 1.e0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kILOH-tBtao-"
   },
   "outputs": [],
   "source": [
    "class RHMF():\n",
    "    def __init__(self, rank, nsigma, tol=1.e-4):\n",
    "        self.K = int(rank)\n",
    "        self.nsigma = float(nsigma)\n",
    "        self.Q2 = self.nsigma ** 2\n",
    "        self.tol = tol\n",
    "        self.trained = False\n",
    "\n",
    "    def train(self, data, weights):\n",
    "        \"\"\"\n",
    "        # inputs:\n",
    "        `data`:     (N, M) array of observations.\n",
    "        `weights`:  (N, M) units of (and equivalent to) inverse uncertainty variances.\n",
    "\n",
    "        # comments:\n",
    "        - Checks convergence with the g-step only.\n",
    "        \"\"\"\n",
    "        self.trained = False\n",
    "        assert np.all(jnp.isfinite(data))\n",
    "        assert np.all(jnp.isfinite(weights))\n",
    "        self.Y = jnp.array(data)\n",
    "        self.input_W = jnp.array(weights)\n",
    "        assert self.Y.shape == self.input_W.shape\n",
    "        self.N, self.M = self.Y.shape\n",
    "        self.converged = False\n",
    "        self.n_iter = 0\n",
    "        self._initialize()\n",
    "        print(\"train(): before starting:\", self.objective(), self.original_objective())\n",
    "        while not self.converged:\n",
    "            self._A_step()\n",
    "            self._G_step()\n",
    "            self._affine()\n",
    "            self._update_W()\n",
    "            self.n_iter += 1\n",
    "            if self.n_iter % 100 == 0:\n",
    "                print(\"train(): after iteration\", self.n_iter, \":\",\n",
    "                      self.objective(), self.original_objective())\n",
    "        print(\"train(): converged at iteration\", self.n_iter, \":\",\n",
    "              self.objective(), self.original_objective())\n",
    "        self.trained = True\n",
    "\n",
    "    def test(self, ystar, wstar):\n",
    "        \"\"\"\n",
    "        # inputs:\n",
    "        `ystar`:     (M, ) array for one observation.\n",
    "        `wstar`:     (M, ) units of (and equivalent to) inverse uncertainty variances.\n",
    "\n",
    "        # outputs:\n",
    "        `synth`:     (M, ) synthetic spectrum.\n",
    "\n",
    "        # comments:\n",
    "        - Checks convergence with the a-step only.\n",
    "        \"\"\"\n",
    "        assert self.trained\n",
    "        assert np.all(np.isfinite(ystar))\n",
    "        assert np.all(np.isfinite(wstar))\n",
    "        assert ystar.shape == (self.M, )\n",
    "        assert wstar.shape == (self.M, )\n",
    "        self.converged = False\n",
    "        self.n_iter = 0\n",
    "        w = 1. * wstar\n",
    "        a = np.zeros(self.K)\n",
    "        while not self.converged:\n",
    "            foo = self.one_star_objective(ystar, w, a)\n",
    "            a = self._one_star_A_step(ystar, w)\n",
    "            bar = self.one_star_objective(ystar, w, a)\n",
    "            if foo - bar < self.tol:\n",
    "                self.converged = True\n",
    "            w = self._update_one_star_W(ystar, wstar, a)\n",
    "            self.n_iter += 1\n",
    "        print(\"test(): converged at iteration:\", self.n_iter, \":\",\n",
    "              self.one_star_objective(ystar, w, a),\n",
    "              self.one_star_objective(ystar, wstar, a))\n",
    "        return self.one_star_synthesis(a)\n",
    "\n",
    "    def synthesis(self):\n",
    "        return self.A.T @ self.G\n",
    "\n",
    "    def one_star_synthesis(self, a):\n",
    "        return a @ self.G\n",
    "\n",
    "    def resid(self):\n",
    "        return self.Y - self.synthesis()\n",
    "\n",
    "    def one_star_resid(self, y, a):\n",
    "        return y - self.one_star_synthesis(a)\n",
    "\n",
    "    def objective(self):\n",
    "        return jnp.sum(self.W * self.resid() ** 2)\n",
    "\n",
    "    def one_star_objective(self, y, w, a):\n",
    "        return jnp.sum(w * self.one_star_resid(y, a) ** 2)\n",
    "\n",
    "    def original_chi(self):\n",
    "        return jnp.sqrt(self.input_W) * self.resid()\n",
    "\n",
    "    def original_objective(self):\n",
    "        return jnp.sum(self.input_W * self.resid() ** 2)\n",
    "\n",
    "    def _initialize(self):\n",
    "        \"\"\"\n",
    "        # bugs:\n",
    "        - Consider switching SVD to a fast PCA implementation?\n",
    "        \"\"\"\n",
    "        self.W = 1. * self.input_W # copy not reference\n",
    "        u, s, v = jnp.linalg.svd(self.Y, full_matrices=False) # maybe slow\n",
    "        self.A = (u[:,:self.K] * s[:self.K]).T\n",
    "        self.G = v[:self.K,:]\n",
    "        print(\"_initialize():\", self.A.shape, self.G.shape)\n",
    "\n",
    "    def _one_star_A_step(self, y1, w1):\n",
    "        XTCinvX = self.G * w1 @ self.G.T\n",
    "        XTCinvY = self.G * w1 @ y1\n",
    "        return jnp.linalg.solve(XTCinvX, XTCinvY)\n",
    "\n",
    "    def _one_star_G_step(self, y1, w1):\n",
    "        XTCinvX = self.A * w1 @ self.A.T\n",
    "        XTCinvY = self.A * w1 @ y1\n",
    "        return jnp.linalg.solve(XTCinvX, XTCinvY)\n",
    "\n",
    "    def _A_step(self):\n",
    "        foo = self.objective()\n",
    "        self.A = jax.vmap(self._one_star_A_step)(self.Y, self.W).T\n",
    "        bar = self.objective()\n",
    "        if foo < bar:\n",
    "            print(\"_A_step(): ERROR: objective got worse\", foo, bar)\n",
    "\n",
    "    def _G_step(self):\n",
    "        foo = self.objective()\n",
    "        self.G = jax.vmap(self._one_star_G_step)(self.Y.T, self.W.T).T\n",
    "        bar = self.objective()\n",
    "        if foo < bar:\n",
    "            print(\"_G_step(): ERROR: objective got worse\", foo, bar)\n",
    "        if foo - bar < self.tol:\n",
    "            self.converged = True\n",
    "\n",
    "    def _affine(self):\n",
    "        \"\"\"\n",
    "        # bugs:\n",
    "        - Consider switching SVD to a fast PCA implementation?\n",
    "        \"\"\"\n",
    "        u, s, v = jnp.linalg.svd(self.A.T @ self.G, full_matrices=False)\n",
    "        self.A = (u[:,:self.K] * s[:self.K]).T\n",
    "        self.G = v[:self.K,:]\n",
    "\n",
    "    def _update_W(self):\n",
    "        self.W = self.input_W * self.Q2 / (self.input_W * self.resid() ** 2 + self.Q2)\n",
    "\n",
    "    def _update_one_star_W(self, y, w, a):\n",
    "        return w * self.Q2 / (w * self.one_star_resid(y, a) ** 2 + self.Q2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "rng = np.random.default_rng(17)\n",
    "rr = rng.uniform(size=len(source_ids))\n",
    "A = rr < np.median(rr)\n",
    "B = np.logical_not(A)\n",
    "YA, WA, source_ids_A = Y[A], W[A], source_ids[A]\n",
    "YB, WB, source_ids_B = Y[B], W[B], source_ids[B]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9kxBDYApYwL-"
   },
   "outputs": [],
   "source": [
    "k, nsigma = 15, 3.0\n",
    "modelA = RHMF(k, nsigma)\n",
    "modelA.train(YA, WA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2BCii8esZsIx"
   },
   "outputs": [],
   "source": [
    "def plot_components(model, title, savefig=None):\n",
    "    for k, g in enumerate(modelA.G):\n",
    "        plt.plot(wavelength_grid, g + 0.15 * k)\n",
    "    plt.xlabel(\"wavelength\")\n",
    "    plt.ylabel(\"spectral component (plus offset)\")\n",
    "    plt.title(title)\n",
    "    if savefig is not None:\n",
    "        plt.savefig(savefig)\n",
    "\n",
    "plot_components(modelA, \"model A\", savefig=\"modelA.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelB = RHMF(k, nsigma)\n",
    "modelB.train(YB, WB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_components(modelB, \"model B\", savefig=\"modelB.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthB = np.zeros_like(YB) + np.nan\n",
    "for i, (y, w) in enumerate(zip(YB, WB)):\n",
    "    synthB[i] = modelA.test(y, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii = 23\n",
    "plt.plot(wavelength_grid, synthB[ii], \"r-\", lw=1, alpha=0.5)\n",
    "plt.plot(wavelength_grid, YB[ii], \"k-\")\n",
    "plt.plot(wavelength_grid, YB[ii] - synthB[ii], \"k-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP+aB/is81+OGHVYDpVC1JW",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
